# HTTP
## GET/POST
- Get 请求能缓存，Post 不能
- Post 相对 Get 安全一点点，因为Get 请求都包含在 URL 里，且会被浏览器保存历史纪录，Post 不会，但是在抓包的情况下都是一样的。
- Post 可以通过 request body来传输比 Get 更多的数据，Get 没有这个技术
- URL有长度限制，会影响 Get 请求，但是这个长度限制是浏览器规定的，不是 RFC 规定的
- Post 支持更多的编码类型且不对数据类型限制

## Status Code
- 100 临时响应, 通知客户端的，部分的请求服务器已经接受，但是客户端应继续发送求 请求的剩余部分.
- 200 OK
- 202 表示服务器已经接受了请求，但是还没有处理，而且这个请求最终 会不会处理还不确定
- 204 表示请求成功，但响应报文不含实体的主体部分
- 205 与 204 类似，不同在于要求请求方重置内容
- 301 永久性重定向，表示资源已被分配了新的 URL
- 302 临时性重定向
- 303  临时性重定向，`且总是使用 GET 请求新的 URI`。
- 304 表示服务器允许访问资源，文档的内容并没有改变，则服务器返回304状态码。304响应不包含消息体，因此以消息头后的第一个空行结尾。
- 307 状态码就是301、302原本需要遵守的规定，除GET、HEAD方法外，其他的请求方法必须等客户确认才能跳转。
- 400 请求报文存在语法错误
- 401 需要有通过 HTTP 认证的认证信息
- 403 表示对请求资源的访问被服务器拒绝
- 404 没有找到请求的资源
- 500 表示服务器端在执行请求时发生了错误
- 501 表示服务器不支持当前请求所需要的某个功能
- 503 表明服务器暂时处于超负载或正在停机维护，无法处理请求


## 部分头信息
- Host，所有请求都带，描述请求将被发送的目的地，包括，且仅仅包括域名和端口号。
- Origin，用来说明请求从哪里发起的，包括，且仅仅包括协议和域名。
  - 这个参数一般只存在于CORS跨域请求中，可以看到response有对应的header：Access-Control-Allow-Origin。
- Referer
  - 告知服务器请求的原始资源的URI，其用于所有类型的请求，并且包括：协议+域名+查询参数（注意，不包含锚点信息）。
  - 因为原始的URI中的查询参数可能包含ID或密码等敏感信息，如果写入referer，则可能导致信息泄露。
### Request
- Accept：向服务器申明客户端（浏览器）可以接受的媒体类型（MIME）的资源
- Accept-encoding：编码
- Cookie
- User-agent：向服务器发送浏览器的版本、系统、应用程序的信息。
- Cache-Control：响应请求都带，在请求头上带，表示本次请求xxx。

### Response
- Content-encoding：压缩类型
- Content-type：媒体资源类型
- Date：设置响应被服务器创建的时间
- Expires：设置响应体的过期时间。
- Cache-control：控制强缓存，响应头上带，表示客户端不要xxx
- Etag：资源hash值
- Last-modified：设置该文件在服务器端中最后被修改的时间
- Set-cookie: 设置 http 的 Cookie
- Status: 200
- Access-Control-Allow-Origin: cors


### 一个图片 url 访问后直接下载怎样实现?
```js
x-oss-object-type: Normal
x-oss-request-id: 598D5ED34F29D01FE2925F41
x-oss-storage-class: Standard

```

# HTTP2.0
## 二进制传输
- 之前的 HTTP 版本中，我们是通过文本的方式传输数据。在 HTTP 2.0 中引入了新的编码机制，所有传输的数据都会被分割，并采用二进制格式编码。

## 多路复用
- 多路复用，就是在一个 TCP 连接中可以存在多条流。换句话说，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。

## Header 压缩
- 在 HTTP 1.X 中，我们使用文本的形式传输 header，在 header 携带 cookie 的情况下，可能每次都需要重复传输几百到几千的字节。
- 在 HTTP 2.0 中，使用了 HPACK 压缩格式对传输的 header 进行编码，减少了 header 的大小。
- 并在两端维护了索引表，用于记录出现过的 header ，后面在传输过程中就可以传输已经记录过的 header 的键名，对端收到数据后就可以通过键名找到对应的值。

## 服务端 Push
- 在 HTTP 2.0 中，服务端可以在客户端某个请求后，主动推送其他资源（比如一定就请求的部分资源）。

# Https
## 可以理解为HTTP+SSL/TLS， 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL，用于安全的 HTTP 数据传输。
## HTTP存在窃听、篡改、冒充的风险
## 过程
![https](../img/https.jpeg)
### 证书验证阶段（非对称加密）
- Client发起Https请求
- Server返回SSL证书（包含CA等信息），证书的签名hash加密
- Client对证书的真伪进行校验
  - 读取证书信息有效期等校验
  - 查找是否是受信任的证书发布机构CA，
  - 找到了，取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密
  - 比对后取出证书中的公钥用于后续加密

### 数据传输阶段（对称加密）
- 证书验证完成，Client本地生成一个随机数，用公钥加密后，传给Server
- Server解密得到随机数，根据这个随机数构造对称加密算法，对内容加密

### 数字签名的制作过程：
- CA拥有非对称加密的私钥和公钥。
- CA对证书明文信息进行hash。对hash后的值用私钥加密，得到数字签名。

### 浏览器验证证书过程：
- 拿到证书，得到明文T，数字签名S。
- 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。
- 用证书里说明的hash算法对明文T进行hash得到T’。
- 比较S’是否等于T’，等于则表明证书可信。

### 大致流程
1. C->S SSL版本，对称算法列表，随机数1
2. S->C 决定使用的SSL版本，对称算法具体内容，随机数2，证书（数字签名和明文）
3. C 进行证书的认证
4. C->S 随机3，hash（1、2明文结果）值
5. S 也能知道1、2的结果，用hash结果比较下，如果符合就把随机数1、2、3计算出一个k，这个k不走传输了保留在本地
6. S->C hash(1、2、4明文结果)值
7. C 也去hash(1、2、4明文结果)值比较下对不对，之后根据手上的随机数1、2、3计算出k


### http1.1、http2和http3差异，有做什么优化
#### http1.1
- 增加了keep-alive长连接
  - 优点：Keep-Alive模式更加高效，因为避免了连接建立和释放的开销。
  - 缺点：长时间的Tcp连接容易导致系统资源无效占用，浪费系统资源。
  - 根据`Content-Length`表示的内容来判断是否失效
- 管线化发送请求，不用等一个请求回来再发另外一个请求
  - 允许多个HTTP请求通过一个套接字同时被输出 ，而不用等待相应的响应。
  - 然后请求者就会等待各自的响应，这些响应是按照之前请求的顺序依次到达。
- 提供了可以指定发送长度的数据块,请求头引入了 range 头域

#### http2
- 数据传输：二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效，切片
- 多路复用：
  - 就是在一个 TCP 连接中可以存在多条流。也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求进行重组。
  - 通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。
  - keep-alive不能解决的问题
    - 不能切片，也就是说，a文件传完才能b文件
    - 连接数过多。
- 头部压缩：
  - HTTP 1.1 不支持 Header 数据压缩，HTTP/2 使用 HPACK 算法对 Header 的数据进行压缩，使得数据传输更快
- 服务器推送（Server Push）：
  - 当对支持 HTTP/2 的服务器请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到服务器，这种方式适用于加载静态资源，节约带宽

#### http3
- QUIC协议
- 基于UDP，整合了 TCP、TLS 和 HTTP/2 的优 点，并加以优化。
- 减少了握手的延迟(1-RTT 或 0-RTT)
- 多路复用，并且没有 TCP 的阻塞问题

#### 队首阻塞问题
- HTTP/1.1 和 HTTP/2 都存在队头阻塞问题(Head of line blocking)
- HTTP/1.1 的队头阻塞。
  - 一个 TCP 连接管道同时传输 10 个请求，其中第 1、2、3 个请求已被客户端接收，但第 4 个请求丢失，那么后面第 5 - 10 个请求都被阻塞，需要等第 4 个请求处理完毕才能被处理，这样 就浪费了带宽资源。
- HTTP/2 的多路复用虽然可以解决“请求”这个粒度的阻塞，但 HTTP/2 的基础 TCP 协议、TLS 协议本身却也存在着队头阻塞的问题。
- 队头阻塞会导致 HTTP/2 在更容易丢包的弱网络环境下比 HTTP/1.1 更慢。
  - HTTP2 在一个 TCP 连接上同时发送 4 个 Stream。其中 Stream1 已经正确到达，并被应用层读取。
  - 但是 Stream2 的第三个 tcp segment 丢失了，TCP 为了保证数据的可靠性，需要发送端重传第 3 个 segment 才能通知应用层读取接下去的数据，虽然这个时候 Stream3 和 Stream4 的全部数据已经到达了接收端，但都被阻塞住了。
- 那 QUIC 解决队头阻塞问题的的方法:
  1. QUIC 的传输单元是 Packet，加密单元也是 Packet，整个加密、 传输、解密都基于 Packet，这样就能避免 TLS 的队头阻塞问题;
  2. QUIC 基于 UDP，UDP 的数据包在接收端没有处理顺序，即使中间 丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理。
  - QUIC 一个连接上的多个 stream 之间没有依赖。这样假如 stream2 丢了一个 udp packet，也只会影响 stream2 的处理。不会影响 stream2 之前及之后的 stream 的处理。



## Cookie
### Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。
- Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。
- 当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。
- 服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。

